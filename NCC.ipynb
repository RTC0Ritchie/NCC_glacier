{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv2\n",
    "from numpy.core import asarray, zeros, swapaxes, take\n",
    "from numpy.core.multiarray import normalize_axis_index\n",
    "from numpy.fft import _pocketfft_internal as pfi\n",
    "from scipy.optimize import curve_fit\n",
    "import pandas as pd\n",
    "import os\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Image storage\n",
    "class matchimg:\n",
    "    '''\n",
    "    img_old: name of the reference image (older)\n",
    "    img_new: name of the secondary image (newer)\n",
    "    fold: address of the images\n",
    "    '''\n",
    "    def __init__(self,fold_urf,img_old_urf,img_new_urf):\n",
    "        self.img_old = img_old_urf\n",
    "        self.img_new = img_new_urf\n",
    "        self.fold = fold_urf\n",
    "\n",
    "    # read two images\n",
    "    def read_img(self):\n",
    "        self.img_old = cv2.imread(self.fold+self.img_old, cv2.IMREAD_GRAYSCALE)\n",
    "        self.img_new = cv2.imread(self.fold+self.img_new, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "# Fourier NCC\n",
    "class img2vxy_fourier:\n",
    "    '''\n",
    "    imas: two images (class)\n",
    "    delta_x/y: temporary displacement x/y\n",
    "    lengthxy: size of results\n",
    "    ker_size: size of search window\n",
    "    win_size: size of search range\n",
    "    startxy: topleft point of the result\n",
    "    isprocessed: temporary data\n",
    "    foldurf: target address of results\n",
    "    finish/err_name_urf: temporary data\n",
    "    '''\n",
    "    def __init__(self,matchimg,ker_size,win_size,startxy,lengthxy,\n",
    "                 foldurf,finish_name_urf,err_name_urf):\n",
    "        self.imgs = matchimg\n",
    "        self.delta_x = np.zeros((lengthxy[0],lengthxy[1]))\n",
    "        self.delta_y = np.zeros((lengthxy[0],lengthxy[1]))\n",
    "        self.lengthxy = lengthxy\n",
    "        self.ker_size = ker_size\n",
    "        self.win_size = win_size\n",
    "        self.startxy = startxy\n",
    "        self.isprocessed = np.zeros_like(self.delta_x)\n",
    "\n",
    "        self.foldurf = foldurf\n",
    "        self.finish_name_urf = finish_name_urf\n",
    "        self.err_name_urf = err_name_urf\n",
    "\n",
    "    #..........................................................\n",
    "    '''\n",
    "    Fourier algorithm of NCC\n",
    "    Reference: https://blog.csdn.net/djq_313/article/details/131178037\n",
    "    '''\n",
    "    def raw_fft(self,a, n, axis, is_real, is_forward, inv_norm):\n",
    "        axis = normalize_axis_index(axis, a.ndim)\n",
    "        if n is None:\n",
    "            n = a.shape[axis]\n",
    "\n",
    "        fct = 1/inv_norm\n",
    "\n",
    "        if a.shape[axis] != n:\n",
    "            s = list(a.shape)\n",
    "            index = [slice(None)]*len(s)\n",
    "            if s[axis] > n:\n",
    "                index[axis] = slice(0, n)\n",
    "                a = a[tuple(index)]\n",
    "            else:\n",
    "                index[axis] = slice(0, s[axis])\n",
    "                s[axis] = n\n",
    "                z = zeros(s, a.dtype.char)\n",
    "                z[tuple(index)] = a\n",
    "                a = z\n",
    "\n",
    "        if axis == a.ndim-1:\n",
    "            r = pfi.execute(a, is_real, is_forward, fct)\n",
    "        else:\n",
    "            a = swapaxes(a, axis, -1)\n",
    "            r = pfi.execute(a, is_real, is_forward, fct)\n",
    "            r = swapaxes(r, axis, -1)\n",
    "        return r\n",
    "    def fft(self,a, n=None, axis=-1):\n",
    "        a = asarray(a)\n",
    "        if n is None:\n",
    "            n = a.shape[axis]\n",
    "        inv_norm = 1\n",
    "        output = self.raw_fft(a, n, axis, False, True, inv_norm)\n",
    "        return output\n",
    "    def ifft(self,a, n=None, axis=-1):\n",
    "        a = asarray(a)\n",
    "        if n is None:\n",
    "            n = a.shape[axis]\n",
    "        inv_norm = n\n",
    "        output = self.raw_fft(a, n, axis, False, False, inv_norm)\n",
    "        return output\n",
    "    def cook_nd_args(self,a, shape=None, axes=None, invreal=0):\n",
    "        if shape is None:\n",
    "            shapeless = 1\n",
    "            if axes is None:\n",
    "                shape = list(a.shape)\n",
    "            else:\n",
    "                shape = take(a.shape, axes)\n",
    "        else:\n",
    "            shapeless = 0\n",
    "        shape = list(shape)\n",
    "        if axes is None:\n",
    "            axes = list(range(-len(shape), 0))\n",
    "        if invreal and shapeless:\n",
    "            shape[-1] = (a.shape[axes[-1]] - 1) * 2\n",
    "        return shape, axes\n",
    "    def raw_fftnd(self,a, shape=None, axes=None, function=fft):\n",
    "        a = asarray(a)\n",
    "        shape, axes = self.cook_nd_args(a, shape, axes)\n",
    "        itl = list(range(len(axes)))\n",
    "        itl.reverse()\n",
    "        for ii in itl:\n",
    "            a = function(a, n=shape[ii], axis=axes[ii])\n",
    "        return a\n",
    "    def imagefft2(self,a, shape=None, axes=(-2, -1)):\n",
    "        return self.raw_fftnd(a, shape, axes, self.fft)\n",
    "    def imageifft2(self,a, shape=None, axes=(-2, -1)):\n",
    "        return self.raw_fftnd(a, shape, axes, self.ifft)\n",
    "    #..........................................................\n",
    "\n",
    "    # Use Fourier to get CI matrix\n",
    "    def fft2CI(self,ker,win):\n",
    "        win_height, win_width = win.shape\n",
    "        #Fourier function\n",
    "        t_fft = self.imagefft2(ker, shape=(win_height, win_width))\n",
    "        o_fft = self.imagefft2(win)\n",
    "        ci = self.imageifft2(np.multiply(o_fft, t_fft.conj()) / np.abs(np.multiply(o_fft, t_fft.conj())))\n",
    "        return ci.real\n",
    "\n",
    "    # Find the first n maximum number\n",
    "    def top_n_indices_2d(self,arr, n):\n",
    "        flat_indices = np.argpartition(arr.ravel(), -n)[-n:]\n",
    "        indices = np.unravel_index(flat_indices, arr.shape)\n",
    "        values = arr[indices]\n",
    "        return indices[0],indices[1],values\n",
    "\n",
    "    # Judging whether the matching is successful by the relationship between the first n maximum values and coefficients\n",
    "    def is_matchpoint(self,ci,n):\n",
    "        index_x,index_y,index_ci = self.top_n_indices_2d(ci,n)\n",
    "        # cimean = np.mean(ci)\n",
    "        # cistd = np.std(ci)\n",
    "        # index_ci = (index_ci-cimean)/cistd\n",
    "        ci_max_idx = np.where(index_ci == np.max(index_ci))[0][0]\n",
    "\n",
    "        degree = 0  #Evaluation criteria: degree of deviation\n",
    "        for ii in range(n):\n",
    "            if ii==ci_max_idx:\n",
    "                continue\n",
    "            if (index_x[ii]-index_x[ci_max_idx])**2 + (index_y[ii]-index_y[ci_max_idx])**2<=5:\n",
    "                continue\n",
    "            degree += 1/abs(index_ci[ii]-index_ci[ci_max_idx])\n",
    "        return degree/n\n",
    "\n",
    "    # Find the index where the maximum value is located\n",
    "    def findmax(self,ci):\n",
    "        def parabola_fit(x, a, b, c, d, e, f):\n",
    "            return (a*x[0]**2 + b*x[1]**2 + c*x[0]*x[1] + d*x[0] + e*x[1] + f).ravel()\n",
    "\n",
    "        result = np.where(ci == np.amax(ci))\n",
    "        result = np.array(list(zip(result[0], result[1]))[0])\n",
    "        ci_size = ci.shape\n",
    "        if np.any(np.logical_or(result>=ci_size[0]-2,result<=1)):\n",
    "            return np.nan,np.nan\n",
    "        new_ci = ci[result[0]-2:result[0]+3,result[1]-2:result[1]+3]*100\n",
    "        para_xy = np.indices([5,5])-2\n",
    "        para_z = new_ci.flatten()\n",
    "        para_popt, _ = curve_fit(parabola_fit, para_xy, para_z)\n",
    "\n",
    "        para_A = np.array([[2*para_popt[0],para_popt[2]],[para_popt[2],2*para_popt[1]]])\n",
    "        para_b = np.array([-para_popt[3],-para_popt[4]])\n",
    "        para_solvexy = np.linalg.solve(para_A,para_b)\n",
    "\n",
    "        if para_solvexy[0]**2 + para_solvexy[1]**2>8:\n",
    "            return np.nan,np.nan\n",
    "        return result[1]+para_solvexy[1],result[0]+para_solvexy[0]\n",
    "\n",
    "    # Store files\n",
    "    def auto_middle_save(self,name_urf):\n",
    "        df = pd.DataFrame(self.delta_x)\n",
    "        df.to_csv(self.foldurf+name_urf[0]+'.csv', index=False)\n",
    "        df = pd.DataFrame(self.delta_y)\n",
    "        df.to_csv(self.foldurf+name_urf[1]+'.csv', index=False)\n",
    "        df = pd.DataFrame(self.isprocessed)\n",
    "        df.to_csv(self.foldurf+name_urf[2]+'.csv', index=False)\n",
    "\n",
    "    # Registration\n",
    "    def matchprocess(self):\n",
    "        start_time = time.time()\n",
    "        for ii in tqdm(range(self.lengthxy[0])):\n",
    "            for jj in range(self.lengthxy[1]):\n",
    "                if self.isprocessed[ii,jj]:\n",
    "                    continue\n",
    "                imgker = self.imgs.img_old[self.startxy[0]+ii-self.ker_size//2:self.startxy[0]+ii+self.ker_size//2,\n",
    "                                           self.startxy[1]+jj-self.ker_size//2:self.startxy[1]+jj+self.ker_size//2]\n",
    "                imgwin = self.imgs.img_new[self.startxy[0]+ii-self.win_size//2:self.startxy[0]+ii+self.win_size//2,\n",
    "                                           self.startxy[1]+jj-self.win_size//2:self.startxy[1]+jj+self.win_size//2]\n",
    "                ci = self.fft2CI(imgker,imgwin)\n",
    "                if np.isnan(ci[0,0]):\n",
    "                    self.delta_x[ii,jj],self.delta_y[ii,jj] = np.nan,np.nan\n",
    "                    # print(f'{self.startxy[0]+ii} , {self.startxy[1]+jj} is missing')\n",
    "                    self.isprocessed[ii,jj] = 2\n",
    "                    continue\n",
    "                degree = self.is_matchpoint(ci,5)  #first n maximum number\n",
    "                if degree > 150:  #threshold of the degree\n",
    "                    self.delta_x[ii,jj],self.delta_y[ii,jj] = np.nan,np.nan\n",
    "                    self.isprocessed[ii,jj] = 2\n",
    "                    continue\n",
    "                tmpdx,tmpdy = self.findmax(ci)\n",
    "                self.delta_x[ii,jj],self.delta_y[ii,jj] = tmpdx,tmpdy\n",
    "                if np.isnan(tmpdx):\n",
    "                    self.isprocessed[ii,jj] = 2\n",
    "                else:\n",
    "                    self.isprocessed[ii,jj] = 1\n",
    "\n",
    "            loop_time = time.time()-start_time\n",
    "            if loop_time>3600:\n",
    "                self.auto_middle_save(self.err_name_urf)\n",
    "                print('Automatic backup completed every hour!')\n",
    "                start_time = time.time()\n",
    "\n",
    "    # complete process for Fourier NCC\n",
    "    def completeprocess(self,is_after_err=False,past_arr_urf=None):\n",
    "        if is_after_err:\n",
    "            df = pd.read_csv(self.foldurf+past_arr_urf[0]+'.csv')\n",
    "            self.delta_x = np.array(df)\n",
    "\n",
    "            if self.delta_x.shape[0]!=self.lengthxy[0] or self.delta_x.shape[1]!= self.lengthxy[1]:\n",
    "                print('The unfinished task does not match the object! Please check the object parameters!')\n",
    "                print(f'Size of the unfinished task: {self.delta_x.shape}')\n",
    "                print(f'Size of this object: {self.lengthxy[0]} , {self.lengthxy[1]}')\n",
    "                return None\n",
    "\n",
    "            df = pd.read_csv(self.foldurf+past_arr_urf[1]+'.csv')\n",
    "            self.delta_y = np.array(df)\n",
    "\n",
    "            df = pd.read_csv(self.foldurf+past_arr_urf[2]+'.csv')\n",
    "            self.isprocessed = np.array(df)\n",
    "\n",
    "        try:\n",
    "            self.matchprocess()\n",
    "        except KeyboardInterrupt:\n",
    "            print('Keyboard Interrupt!')\n",
    "            self.auto_middle_save(self.err_name_urf)\n",
    "            print('Temporary storage finished.')\n",
    "            return 0\n",
    "        except ZeroDivisionError:\n",
    "            print('Zero Division Error!')\n",
    "            self.auto_middle_save(self.err_name_urf)\n",
    "            print('Temporary storage finished.')\n",
    "            return 0\n",
    "        except IndexError:\n",
    "            print('Index Error!')\n",
    "            self.auto_middle_save(self.err_name_urf)\n",
    "            print('Temporary storage finished.')\n",
    "            return 0\n",
    "        else:\n",
    "            print('Finished!')\n",
    "            self.auto_middle_save(self.finish_name_urf)\n",
    "            print('Storage finished.')\n",
    "            return 1\n",
    "\n",
    "    # Read completed files\n",
    "    def read_finished_vxy(self,name_urf):\n",
    "        df = pd.read_csv(self.foldurf+name_urf[0]+'.csv')\n",
    "        self.delta_x = np.array(df)\n",
    "\n",
    "        if self.delta_x.shape[0]!=self.lengthxy[0] or self.delta_x.shape[1]!= self.lengthxy[1]:\n",
    "            print('The completed task does not match the object! Please check the object parameters!')\n",
    "            print(f'Size of the completed task: {self.delta_x.shape}')\n",
    "            print(f'Size of this object: {self.lengthxy[0]} , {self.lengthxy[1]}')\n",
    "            return None\n",
    "\n",
    "        df = pd.read_csv(self.foldurf+name_urf[1]+'.csv')\n",
    "        self.delta_y = np.array(df)\n",
    "\n",
    "        df = pd.read_csv(self.foldurf+name_urf[2]+'.csv')\n",
    "        self.isprocessed = np.array(df)\n",
    "\n",
    "        return True\n",
    "\n",
    "# Fill in gaps\n",
    "class img2vxy_equal:\n",
    "    '''\n",
    "    imas: two images (class)\n",
    "    delta_x/y: temporary displacement x/y\n",
    "    lengthxy: size of results\n",
    "    ker_size: size of search window\n",
    "    win_size: size of search range\n",
    "    startxy: topleft point of the result\n",
    "    isprocessed: temporary data\n",
    "    foldurf: target address of results\n",
    "    finish/err_name_urf: temporary data\n",
    "    '''\n",
    "    def __init__(self,matchimg,ker_size,win_size,startxy,lengthxy,\n",
    "                 foldurf,finish_name_urf,err_name_urf):\n",
    "        self.imgs = matchimg\n",
    "\n",
    "        self.delta_x = np.zeros((lengthxy[0],lengthxy[1]))\n",
    "        self.delta_y = np.zeros((lengthxy[0],lengthxy[1]))\n",
    "        self.lengthxy = lengthxy\n",
    "        self.ker_size = ker_size\n",
    "        self.win_size = win_size\n",
    "        self.startxy = startxy\n",
    "        self.isprocessed = np.zeros_like(self.delta_x)\n",
    "\n",
    "        self.foldurf = foldurf\n",
    "        self.finish_name_urf = finish_name_urf\n",
    "        self.err_name_urf = err_name_urf\n",
    "\n",
    "\n",
    "    # Read completed Fourier files\n",
    "    def read_fourier_vxy(self,out_foldurf,name_urf,is_used_fourier=False,fourier=None):\n",
    "        # Use the results obtained from exterior Fourier\n",
    "        if not is_used_fourier:\n",
    "            df = pd.read_csv(out_foldurf+name_urf[0]+'.csv')\n",
    "            self.delta_x = np.array(df)-self.win_size//2+self.ker_size//2\n",
    "            if self.delta_x.shape[0]!=self.lengthxy[0] or self.delta_x.shape[1]!= self.lengthxy[1]:\n",
    "                print('The Fourier task does not match this object! Please check the object parameters!')\n",
    "                print(f'Size of Fourier task: {self.delta_x.shape}')\n",
    "                print(f'Size of this object: {self.lengthxy[0]} , {self.lengthxy[1]}')\n",
    "                return None\n",
    "\n",
    "            df = pd.read_csv(out_foldurf+name_urf[1]+'.csv')\n",
    "            self.delta_y = np.array(df)-self.win_size//2+self.ker_size//2\n",
    "\n",
    "            df = pd.read_csv(out_foldurf+name_urf[2]+'.csv')\n",
    "            self.isprocessed = np.array(df)\n",
    "            print('Importing Fourier processing file completed!')\n",
    "        # Use the results obtained from inner Fourier\n",
    "        else:\n",
    "            self.delta_x = fourier.delta_x-self.win_size//2+self.ker_size//2\n",
    "            if self.delta_x.shape[0]!=self.lengthxy[0] or self.delta_x.shape[1]!= self.lengthxy[1]:\n",
    "                print('The Fourier task does not match this object! Please check the object parameters!')\n",
    "                print(f'Size of Fourier task: {self.delta_x.shape}')\n",
    "                print(f'Size of this object: {self.lengthxy[0]} , {self.lengthxy[1]}')\n",
    "                return None\n",
    "            self.delta_y = fourier.delta_y-self.win_size//2+self.ker_size//2\n",
    "            self.isprocessed = fourier.isprocessed\n",
    "            print('Importing Fourier processing memory completed!')\n",
    "\n",
    "    #Clear abnormal data and retain data within the range\n",
    "    def save_range_data(self,dxrange,dyrange):\n",
    "        nanidx = np.where(np.logical_or(np.logical_or(self.delta_x<dxrange[0],self.delta_x>dxrange[1]),\n",
    "                                       np.logical_or(self.delta_y<dyrange[0],self.delta_y>dyrange[1])))\n",
    "        self.delta_x[nanidx] = np.nan\n",
    "        self.delta_y[nanidx] = np.nan\n",
    "        self.isprocessed[nanidx] = 2\n",
    "\n",
    "    # Find the best matching location based on the existing results around the grid\n",
    "    def choose_nearest_distance(self,ii,jj):\n",
    "        radius = 1\n",
    "        tmpstate = 0\n",
    "        maxiter = 0\n",
    "\n",
    "        while not tmpstate:\n",
    "            maxiter+=1\n",
    "            tmp_isprocessed = self.isprocessed[max(0,ii-radius):min(self.isprocessed.shape[0],ii+radius+1),\n",
    "                                               max(0,jj-radius):min(self.isprocessed.shape[1],jj+radius+1)]\n",
    "            tmp_dx = self.delta_x[max(0,ii-radius):min(self.isprocessed.shape[0],ii+radius+1),\n",
    "                                  max(0,jj-radius):min(self.isprocessed.shape[1],jj+radius+1)]\n",
    "            if 2*tmp_isprocessed.shape[0]*tmp_isprocessed.shape[1] - np.sum(tmp_isprocessed) > 5 and (not np.isnan(tmp_dx).all()):\n",
    "                tmpstate = 1\n",
    "            else:\n",
    "                radius += 1\n",
    "            if maxiter>1000:\n",
    "                return 0,0\n",
    "\n",
    "        tmp_isprocessed = self.isprocessed[max(0,ii-radius):min(self.isprocessed.shape[0],ii+radius+1),\n",
    "                                           max(0,jj-radius):min(self.isprocessed.shape[1],jj+radius+1)]\n",
    "\n",
    "        tmp_idx = np.where(tmp_isprocessed==1)\n",
    "\n",
    "        tmp_dx = self.delta_x[max(0,ii-radius):min(self.isprocessed.shape[0],ii+radius+1),\n",
    "                              max(0,jj-radius):min(self.isprocessed.shape[1],jj+radius+1)]\n",
    "        tmp_dx = tmp_dx[tmp_idx[0],tmp_idx[1]]\n",
    "        tmp_ave_dx = np.nanmedian(tmp_dx)\n",
    "\n",
    "        tmp_dy = self.delta_y[max(0,ii-radius):min(self.isprocessed.shape[0],ii+radius+1),\n",
    "                              max(0,jj-radius):min(self.isprocessed.shape[1],jj+radius+1)]\n",
    "        tmp_dy = tmp_dy[tmp_idx[0],tmp_idx[1]]\n",
    "        tmp_ave_dy = np.nanmedian(tmp_dy)\n",
    "\n",
    "        return int(tmp_ave_dx),   int(tmp_ave_dy)\n",
    "\n",
    "    # fill in the gaps\n",
    "    def equalCI(self,img, kernel):\n",
    "        ker_fft = np.fft.fft2(kernel)\n",
    "        win_fft = np.fft.fft2(img)\n",
    "        tmp = np.multiply(ker_fft,win_fft.conj())\n",
    "        tmp = tmp/np.abs(tmp)\n",
    "        tmpCImat = np.fft.ifft2(tmp)\n",
    "        tmpCImat = tmpCImat.real\n",
    "        CIshape = tmpCImat.shape[0]\n",
    "\n",
    "        newCImat = np.zeros_like(tmpCImat)\n",
    "        newCImat[CIshape//2:CIshape,CIshape//2:CIshape] = tmpCImat[:CIshape//2,:CIshape//2]\n",
    "        newCImat[:CIshape//2,CIshape//2:CIshape] = tmpCImat[CIshape//2:CIshape,:CIshape//2]\n",
    "        newCImat[CIshape//2:CIshape,:CIshape//2] = tmpCImat[:CIshape//2,CIshape//2:CIshape]\n",
    "        newCImat[:CIshape//2,:CIshape//2] = tmpCImat[CIshape//2:CIshape,CIshape//2:CIshape]\n",
    "        return newCImat\n",
    "\n",
    "    # Find the first n maximum number\n",
    "    def top_n_indices_2d(self,arr, n):\n",
    "        flat_indices = np.argpartition(arr.ravel(), -n)[-n:]\n",
    "        indices = np.unravel_index(flat_indices, arr.shape)\n",
    "        values = arr[indices]\n",
    "        return indices[0],indices[1],values\n",
    "\n",
    "    # Judging whether the matching is successful by the relationship between the first n maximum values and coefficients\n",
    "    def is_matchpoint(self,ci,n):\n",
    "        index_x,index_y,index_ci = self.top_n_indices_2d(ci,n)\n",
    "        # cimean = np.mean(ci)\n",
    "        # cistd = np.std(ci)\n",
    "        # index_ci = (index_ci-cimean)/cistd\n",
    "        ci_max_idx = np.where(index_ci == np.max(index_ci))[0][0]\n",
    "\n",
    "        degree = 0  #Evaluation criteria: degree of deviation\n",
    "        for ii in range(n):\n",
    "            if ii==ci_max_idx:\n",
    "                continue\n",
    "            if (index_x[ii]-index_x[ci_max_idx])**2 + (index_y[ii]-index_y[ci_max_idx])**2<=5:\n",
    "                continue\n",
    "            degree += 1/abs(index_ci[ii]-index_ci[ci_max_idx])\n",
    "        return degree/n\n",
    "\n",
    "    # Find the index where the maximum value is located\n",
    "    def findmax(self,ci):\n",
    "        def parabola_fit(x, a, b, c, d, e, f):\n",
    "            return (a*x[0]**2 + b*x[1]**2 + c*x[0]*x[1] + d*x[0] + e*x[1] + f).ravel()\n",
    "\n",
    "        result = np.where(ci == np.amax(ci))\n",
    "        result = np.array(list(zip(result[0], result[1]))[0])\n",
    "        ci_size = ci.shape\n",
    "        if np.any(np.logical_or(result>=ci_size[0]-2,result<=1)):\n",
    "            return np.nan,np.nan\n",
    "        new_ci = ci[result[0]-2:result[0]+3,result[1]-2:result[1]+3]*100\n",
    "        para_xy = np.indices([5,5])-2\n",
    "        para_z = new_ci.flatten()\n",
    "        para_popt, _ = curve_fit(parabola_fit, para_xy, para_z)\n",
    "\n",
    "        para_A = np.array([[2*para_popt[0],para_popt[2]],[para_popt[2],2*para_popt[1]]])\n",
    "        para_b = np.array([-para_popt[3],-para_popt[4]])\n",
    "        para_solvexy = np.linalg.solve(para_A,para_b)\n",
    "\n",
    "        if para_solvexy[0]**2 + para_solvexy[1]**2>8:\n",
    "            return np.nan,np.nan\n",
    "        return result[1]+para_solvexy[1]-self.ker_size//2,result[0]+para_solvexy[0]-self.ker_size//2\n",
    "\n",
    "\n",
    "    # Registration\n",
    "    def single_match(self,ii,jj):\n",
    "        if self.isprocessed[ii,jj]==1:\n",
    "            return None\n",
    "        dy,dx = self.choose_nearest_distance(ii,jj)\n",
    "        imgker = self.imgs.img_old[self.startxy[0]+ii-self.ker_size//2:self.startxy[0]+ii+self.ker_size//2,\n",
    "                                   self.startxy[1]+jj-self.ker_size//2:self.startxy[1]+jj+self.ker_size//2]\n",
    "        imgwin = self.imgs.img_new[self.startxy[0]+ii-self.ker_size//2+dx:self.startxy[0]+ii+self.ker_size//2+dx,\n",
    "                                   self.startxy[1]+jj-self.ker_size//2+dy:self.startxy[1]+jj+self.ker_size//2+dy]\n",
    "        ci = self.equalCI(imgker,imgwin)\n",
    "        if np.isnan(ci[0,0]):\n",
    "            return None\n",
    "        degree = self.is_matchpoint(ci,5)\n",
    "        if degree > 500:\n",
    "            return None\n",
    "        self.delta_x[ii,jj],self.delta_y[ii,jj] = self.findmax(ci)\n",
    "        if np.isnan(self.delta_x[ii,jj]):\n",
    "            return None\n",
    "        else:\n",
    "            self.delta_x[ii,jj]+=dy\n",
    "            self.delta_y[ii,jj]+=dx\n",
    "            self.isprocessed[ii,jj] = 1\n",
    "            return True\n",
    "\n",
    "    # Store files\n",
    "    def auto_middle_save(self,name_urf):\n",
    "        df = pd.DataFrame(self.delta_x)\n",
    "        df.to_csv(self.foldurf+name_urf[0]+'.csv', index=False)\n",
    "        df = pd.DataFrame(self.delta_y)\n",
    "        df.to_csv(self.foldurf+name_urf[1]+'.csv', index=False)\n",
    "        df = pd.DataFrame(self.isprocessed)\n",
    "        df.to_csv(self.foldurf+name_urf[2]+'.csv', index=False)\n",
    "\n",
    "    # fill in the gaps within the whole file\n",
    "    def ranking_sequence(self,isautosave = True):\n",
    "        for ii in tqdm(np.flip(np.arange(self.delta_x.shape[0]//2))):\n",
    "            for jj in np.flip(np.arange(self.delta_x.shape[1]//2)):\n",
    "                self.single_match(ii,jj)\n",
    "        if isautosave:\n",
    "            self.auto_middle_save(self.err_name_urf)\n",
    "            print('Automatic backup completed!')\n",
    "        for ii in tqdm(np.arange(self.delta_x.shape[0]//2,self.delta_x.shape[0])):\n",
    "            for jj in np.flip(np.arange(self.delta_x.shape[1]//2)):\n",
    "                self.single_match(ii,jj)\n",
    "        if isautosave:\n",
    "            self.auto_middle_save(self.err_name_urf)\n",
    "            print('Automatic backup completed!')\n",
    "        for ii in tqdm(np.flip(np.arange(self.delta_x.shape[0]//2))):\n",
    "            for jj in np.arange(self.delta_x.shape[1]//2,self.delta_x.shape[1]):\n",
    "                self.single_match(ii,jj)\n",
    "        if isautosave:\n",
    "            self.auto_middle_save(self.err_name_urf)\n",
    "            print('Automatic backup completed!')\n",
    "        for ii in tqdm(np.arange(self.delta_x.shape[0]//2,self.delta_x.shape[0])):\n",
    "            for jj in np.arange(self.delta_x.shape[1]//2,self.delta_x.shape[1]):\n",
    "                self.single_match(ii,jj)\n",
    "\n",
    "    # complete process\n",
    "    def completeprocess(self,isautosave=True,is_after_err=False,past_arr_urf=None):\n",
    "        if is_after_err:\n",
    "            df = pd.read_csv(self.foldurf+past_arr_urf[0]+'.csv')\n",
    "            self.delta_x = np.array(df)\n",
    "\n",
    "            if self.delta_x.shape[0]!=self.lengthxy[0] or self.delta_x.shape[1]!= self.lengthxy[1]:\n",
    "                print('The unfinished task does not match the object! Please check the object parameters!')\n",
    "                print(f'Size of the unfinished task: {self.delta_x.shape}')\n",
    "                print(f'Size of this object: {self.lengthxy[0]} , {self.lengthxy[1]}')\n",
    "                return None\n",
    "\n",
    "            df = pd.read_csv(self.foldurf+past_arr_urf[1]+'.csv')\n",
    "            self.delta_y = np.array(df)\n",
    "\n",
    "            df = pd.read_csv(self.foldurf+past_arr_urf[2]+'.csv')\n",
    "            self.isprocessed = np.array(df)\n",
    "\n",
    "        try:\n",
    "            self.ranking_sequence(isautosave)\n",
    "        except KeyboardInterrupt:\n",
    "            print('Keyboard Interrupt!')\n",
    "            self.auto_middle_save(self.err_name_urf)\n",
    "            print('Temporary storage finished.')\n",
    "            return 0\n",
    "        except ZeroDivisionError:\n",
    "            print('Zero Division Error!')\n",
    "            self.auto_middle_save(self.err_name_urf)\n",
    "            print('Temporary storage finished.')\n",
    "            return 0\n",
    "        except IndexError:\n",
    "            print('Index Error!')\n",
    "            self.auto_middle_save(self.err_name_urf)\n",
    "            print('Temporary storage finished.')\n",
    "            return 0\n",
    "        else:\n",
    "            print('Finished!')\n",
    "            self.auto_middle_save(self.finish_name_urf)\n",
    "            print('Storage finished.')\n",
    "            return 1\n",
    "\n",
    "    # Read completed files\n",
    "    def read_finished_vxy(self,name_urf):\n",
    "        df = pd.read_csv(self.foldurf+name_urf[0]+'.csv')\n",
    "        self.delta_x = np.array(df)\n",
    "\n",
    "        if self.delta_x.shape[0]!=self.lengthxy[0] or self.delta_x.shape[1]!= self.lengthxy[1]:\n",
    "            print('The completed task does not match the object! Please check the object parameters!')\n",
    "            print(f'Size of the completed task: {self.delta_x.shape}')\n",
    "            print(f'Size of this object: {self.lengthxy[0]} , {self.lengthxy[1]}')\n",
    "            return None\n",
    "\n",
    "        df = pd.read_csv(self.foldurf+name_urf[1]+'.csv')\n",
    "        self.delta_y = np.array(df)\n",
    "\n",
    "        df = pd.read_csv(self.foldurf+name_urf[2]+'.csv')\n",
    "        self.isprocessed = np.array(df)\n",
    "\n",
    "# Register two images for one task\n",
    "class img2vxy:\n",
    "    def __init__(self,ker_size,win_size,startxy,lengthxy,\n",
    "                 img_fold_urf,img_old_urf,img_new_urf,\n",
    "                 foldurf_fourier,finish_name_urf_fourier,err_name_urf_fourier,\n",
    "                 foldurf_equal,finish_name_urf_equal,err_name_urf_equal,\n",
    "                 ):\n",
    "        self.foldurf_fourier = foldurf_fourier\n",
    "        self.finish_name_urf_fourier = finish_name_urf_fourier\n",
    "        self.err_name_urf_fourier = err_name_urf_fourier\n",
    "\n",
    "        self.foldurf_equal = foldurf_equal\n",
    "        self.finish_name_urf_equal = finish_name_urf_equal\n",
    "        self.err_name_urf_equal = err_name_urf_equal\n",
    "\n",
    "        self.imgs = matchimg(img_fold_urf,img_old_urf,img_new_urf)\n",
    "        self.imgs.read_img()\n",
    "\n",
    "        self.fourier = img2vxy_fourier(self.imgs,ker_size,win_size,startxy,lengthxy,\n",
    "                                       foldurf_fourier,finish_name_urf_fourier,err_name_urf_fourier)\n",
    "\n",
    "        self.equal = img2vxy_equal(self.imgs,ker_size,win_size,startxy,lengthxy,\n",
    "                                       foldurf_equal,finish_name_urf_equal,err_name_urf_equal)\n",
    "\n",
    "    # Fourier procession\n",
    "    def process_fourier(self):\n",
    "        if os.path.exists(self.foldurf_fourier+self.finish_name_urf_fourier[0]+'.csv'):\n",
    "            print('Reading Fourier completed task...')\n",
    "            if self.fourier.read_finished_vxy(self.finish_name_urf_fourier) != None:\n",
    "                print('Reading Fourier completed task finished!')\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        elif os.path.exists(self.foldurf_fourier+self.err_name_urf_fourier[0]+'.csv'):\n",
    "            print('Reading Fourier temporary task...')\n",
    "            state = self.fourier.completeprocess(True,self.err_name_urf_fourier)\n",
    "            return state\n",
    "        else:\n",
    "            print('Starting Fourier task...')\n",
    "            state = self.fourier.completeprocess()\n",
    "            return state\n",
    "\n",
    "    # secondary procession\n",
    "    def process_equal(self,day,isautosave = True, is_used_fourier=False):\n",
    "        if os.path.exists(self.foldurf_equal+self.finish_name_urf_equal[0]+'.csv'):\n",
    "            print('Reading secondary completed task...')\n",
    "            if self.equal.read_finished_vxy(self.finish_name_urf_equal) != None:\n",
    "                print('Reading secondary completed task finished!')\n",
    "                return 1\n",
    "            else:\n",
    "                return 0\n",
    "        elif os.path.exists(self.foldurf_equal+self.err_name_urf_equal[0]+'.csv'):\n",
    "            print('Reading secondary temporary task...')\n",
    "            state = self.equal.completeprocess(isautosave=isautosave,is_after_err=True,past_arr_urf=self.err_name_urf_equal)\n",
    "            return state\n",
    "        else:\n",
    "            print('Starting secondary task')\n",
    "            self.equal.read_fourier_vxy(self.foldurf_fourier,self.finish_name_urf_fourier,is_used_fourier,self.fourier)\n",
    "            self.equal.save_range_data([-0.5*day,3*day],[-0.5*day,3*day])\n",
    "            state = self.equal.completeprocess(isautosave=isautosave)\n",
    "            return state\n",
    "\n",
    "# Registration for the whole tasks\n",
    "class process_all:\n",
    "    def __init__(self,basis_fold_urf,sta_name,file_name,picture_add,\n",
    "                 ker_size,win_size,startxy,lengthxy):\n",
    "        self.basis_fold_urf = basis_fold_urf\n",
    "        self.sta_name = sta_name\n",
    "        self.file_name = file_name\n",
    "        self.picture_add = picture_add\n",
    "\n",
    "        self.lengthxy = lengthxy\n",
    "        self.ker_size = ker_size\n",
    "        self.win_size = win_size\n",
    "        self.startxy = startxy\n",
    "\n",
    "        self.initialization()\n",
    "\n",
    "    def initialization(self):\n",
    "        if not os.path.exists(self.basis_fold_urf):\n",
    "            os.makedirs(self.basis_fold_urf)\n",
    "        subfolders = ['datae','dataf']\n",
    "        for sub in subfolders:\n",
    "            sub_path = os.path.join(self.basis_fold_urf, sub)\n",
    "            if not os.path.exists(sub_path):\n",
    "                os.makedirs(sub_path)\n",
    "        file_name, file_ext = os.path.splitext(self.sta_name)\n",
    "        csv_path = f\"{file_name}.csv\"\n",
    "        if os.path.exists(csv_path):\n",
    "            self.sta_name = csv_path\n",
    "            df = pd.read_csv(self.sta_name)\n",
    "            self.all_state_list = np.array(df)\n",
    "            return None\n",
    "        try:\n",
    "            if file_ext.lower() in ['.xlsx', '.xls']:\n",
    "                df = pd.read_excel(self.sta_name)\n",
    "                self.all_state_list = np.array(df)\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                self.sta_name = csv_path\n",
    "            elif file_ext.lower() == '.txt':\n",
    "                df = pd.read_csv(self.sta_name, sep='\\t')\n",
    "                self.all_state_list = np.array(df)\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                self.sta_name = csv_path\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported File Format!\")\n",
    "        except Exception:\n",
    "            print(f\"Please confirm if the **statistics** file format is correct.\")\n",
    "\n",
    "    def forward(self,type,isbreak=True,is_equal_autosave = True):\n",
    "        if type == 'f':\n",
    "            for ii in range(self.all_state_list.shape[0]-1):\n",
    "                if self.all_state_list[ii,1]!=0:\n",
    "                    continue\n",
    "                else:\n",
    "\n",
    "                    v_last = str(self.all_state_list[ii,0])\n",
    "                    v_end = str(self.all_state_list[ii+1,0])\n",
    "                    v_str = v_last+'-'+v_end\n",
    "                    print(f'Start processing: {v_str}')\n",
    "                    finish_name_urf_fourier = [self.file_name[0]+v_str+'_f',self.file_name[1]+v_str+'_f',self.file_name[2]+v_str+'_f']\n",
    "                    err_name_urf_fourier = ['err_'+self.file_name[0]+v_str+'_f','err_'+self.file_name[1]+v_str+'_f','err_'+self.file_name[2]+v_str+'_f']\n",
    "                    finish_name_urf_equal = [self.file_name[0]+v_str+'_e',self.file_name[1]+v_str+'_e',self.file_name[2]+v_str+'_e']\n",
    "                    err_name_urf_equal = ['err_'+self.file_name[0]+v_str+'_e','err_'+self.file_name[1]+v_str+'_e','err_'+self.file_name[2]+v_str+'_e']\n",
    "                    test = img2vxy(self.ker_size,self.win_size,self.startxy,self.lengthxy,\n",
    "                                   self.picture_add,v_last+'.jpg',v_end+'.jpg',\n",
    "                                   self.basis_fold_urf+'dataf/',finish_name_urf_fourier,err_name_urf_fourier,\n",
    "                                   self.basis_fold_urf+'datae/',finish_name_urf_equal,err_name_urf_equal)\n",
    "                    state = test.process_fourier()\n",
    "\n",
    "                    if state:\n",
    "                        df = pd.read_csv(self.sta_name)\n",
    "                        df.iloc[ii, 1] = 1\n",
    "                        df.to_csv(self.sta_name, index=False)\n",
    "                        print(f'{v_str} finished!')\n",
    "                    else:\n",
    "                        print(f'{v_str} temporarily stopped!')\n",
    "                        if isbreak:\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "        if type == 'e':\n",
    "            for ii in range(self.all_state_list.shape[0]-1):\n",
    "                if self.all_state_list[ii,2]!=0:\n",
    "                    continue\n",
    "                else:\n",
    "\n",
    "                    v_last = str(self.all_state_list[ii,0])\n",
    "                    v_end = str(self.all_state_list[ii+1,0])\n",
    "                    v_str = v_last+'-'+v_end\n",
    "                    print(f'Start processing: {v_str}')\n",
    "                    finish_name_urf_fourier = [self.file_name[0]+v_str+'_f',self.file_name[1]+v_str+'_f',self.file_name[2]+v_str+'_f']\n",
    "                    err_name_urf_fourier = ['err_'+self.file_name[0]+v_str+'_f','err_'+self.file_name[1]+v_str+'_f','err_'+self.file_name[2]+v_str+'_f']\n",
    "                    finish_name_urf_equal = [self.file_name[0]+v_str+'_e',self.file_name[1]+v_str+'_e',self.file_name[2]+v_str+'_e']\n",
    "                    err_name_urf_equal = ['err_'+self.file_name[0]+v_str+'_e','err_'+self.file_name[1]+v_str+'_e','err_'+self.file_name[2]+v_str+'_e']\n",
    "                    test = img2vxy(self.ker_size,self.win_size,self.startxy,self.lengthxy,\n",
    "                                   self.picture_add,v_last+'.jpg',v_end+'.jpg',\n",
    "                                   self.basis_fold_urf+'dataf/',finish_name_urf_fourier,err_name_urf_fourier,\n",
    "                                   self.basis_fold_urf+'datae/',finish_name_urf_equal,err_name_urf_equal)\n",
    "                    state = test.process_equal(self.all_state_list[ii,3],isautosave=is_equal_autosave)\n",
    "\n",
    "                    if state:\n",
    "                        df = pd.read_csv(self.sta_name)\n",
    "                        df.iloc[ii, 2] = 1\n",
    "                        df.to_csv(self.sta_name, index=False)\n",
    "                        print(f'{v_str} finished!')\n",
    "                    else:\n",
    "                        print(f'{v_str} temporarily stopped!')\n",
    "                        if isbreak:\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "        if type=='fe':\n",
    "            for ii in range(self.all_state_list.shape[0]-1):\n",
    "                if self.all_state_list[ii,2]!=0:\n",
    "                    continue\n",
    "                elif self.all_state_list[ii,1]!=0:\n",
    "                    v_last = str(self.all_state_list[ii,0])\n",
    "                    v_end = str(self.all_state_list[ii+1,0])\n",
    "                    v_str = v_last+'-'+v_end\n",
    "                    print(f'Start processing: {v_str}')\n",
    "                    finish_name_urf_fourier = [self.file_name[0]+v_str+'_f',self.file_name[1]+v_str+'_f',self.file_name[2]+v_str+'_f']\n",
    "                    err_name_urf_fourier = ['err_'+self.file_name[0]+v_str+'_f','err_'+self.file_name[1]+v_str+'_f','err_'+self.file_name[2]+v_str+'_f']\n",
    "                    finish_name_urf_equal = [self.file_name[0]+v_str+'_e',self.file_name[1]+v_str+'_e',self.file_name[2]+v_str+'_e']\n",
    "                    err_name_urf_equal = ['err_'+self.file_name[0]+v_str+'_e','err_'+self.file_name[1]+v_str+'_e','err_'+self.file_name[2]+v_str+'_e']\n",
    "                    test = img2vxy(self.ker_size,self.win_size,self.startxy,self.lengthxy,\n",
    "                                   self.picture_add,v_last+'.jpg',v_end+'.jpg',\n",
    "                                   self.basis_fold_urf+'dataf/',finish_name_urf_fourier,err_name_urf_fourier,\n",
    "                                   self.basis_fold_urf+'datae/',finish_name_urf_equal,err_name_urf_equal)\n",
    "                    state = test.process_equal(self.all_state_list[ii,3],isautosave=is_equal_autosave)\n",
    "\n",
    "                    if state:\n",
    "                        df = pd.read_csv(self.sta_name)\n",
    "                        df.iloc[ii, 2] = 1\n",
    "                        df.to_csv(self.sta_name, index=False)\n",
    "                        print(f'{v_str} finished!')\n",
    "                    else:\n",
    "                        print(f'{v_str} temporarily stopped!')\n",
    "                        if isbreak:\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "                else:\n",
    "\n",
    "                    v_last = str(self.all_state_list[ii,0])\n",
    "                    v_end = str(self.all_state_list[ii+1,0])\n",
    "                    v_str = v_last+'-'+v_end\n",
    "                    print(f'Start processing: {v_str}')\n",
    "                    finish_name_urf_fourier = [self.file_name[0]+v_str+'_f',self.file_name[1]+v_str+'_f',self.file_name[2]+v_str+'_f']\n",
    "                    err_name_urf_fourier = ['err_'+self.file_name[0]+v_str+'_f','err_'+self.file_name[1]+v_str+'_f','err_'+self.file_name[2]+v_str+'_f']\n",
    "                    finish_name_urf_equal = [self.file_name[0]+v_str+'_e',self.file_name[1]+v_str+'_e',self.file_name[2]+v_str+'_e']\n",
    "                    err_name_urf_equal = ['err_'+self.file_name[0]+v_str+'_e','err_'+self.file_name[1]+v_str+'_e','err_'+self.file_name[2]+v_str+'_e']\n",
    "                    test = img2vxy(self.ker_size,self.win_size,self.startxy,self.lengthxy,\n",
    "                                   self.picture_add,v_last+'.jpg',v_end+'.jpg',\n",
    "                                   self.basis_fold_urf+'dataf/',finish_name_urf_fourier,err_name_urf_fourier,\n",
    "                                   self.basis_fold_urf+'datae/',finish_name_urf_equal,err_name_urf_equal)\n",
    "                    state = test.process_fourier()\n",
    "                    if state:\n",
    "                        df = pd.read_csv(self.sta_name)\n",
    "                        df.iloc[ii, 1] = 1\n",
    "                        df.to_csv(self.sta_name, index=False)\n",
    "                        print(f'{v_str} finished!')\n",
    "                    else:\n",
    "                        print(f'{v_str} temporarily stopped!')\n",
    "                        if isbreak:\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    state = test.process_equal(self.all_state_list[ii,3],isautosave=is_equal_autosave,is_used_fourier=True)\n",
    "                    if state:\n",
    "                        df = pd.read_csv(self.sta_name)\n",
    "                        df.iloc[ii, 2] = 1\n",
    "                        df.to_csv(self.sta_name, index=False)\n",
    "                        print(f'{v_str} finished!')\n",
    "                    else:\n",
    "                        print(f'{v_str} temporarily stopped!')\n",
    "                        if isbreak:\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "        if type=='dfe': #double\n",
    "            for ii in range(self.all_state_list.shape[0]):\n",
    "                if self.all_state_list[ii,4]!=0:\n",
    "                    continue\n",
    "                elif self.all_state_list[ii,3]!=0:\n",
    "                    v_last = str(self.all_state_list[ii,0])\n",
    "                    v_end = str(self.all_state_list[ii,1])\n",
    "                    v_str = v_last+'-'+v_end\n",
    "                    print(f'Start processing: {v_str}')\n",
    "                    finish_name_urf_fourier = [self.file_name[0]+v_str+'_f',self.file_name[1]+v_str+'_f',self.file_name[2]+v_str+'_f']\n",
    "                    err_name_urf_fourier = ['err_'+self.file_name[0]+v_str+'_f','err_'+self.file_name[1]+v_str+'_f','err_'+self.file_name[2]+v_str+'_f']\n",
    "                    finish_name_urf_equal = [self.file_name[0]+v_str+'_e',self.file_name[1]+v_str+'_e',self.file_name[2]+v_str+'_e']\n",
    "                    err_name_urf_equal = ['err_'+self.file_name[0]+v_str+'_e','err_'+self.file_name[1]+v_str+'_e','err_'+self.file_name[2]+v_str+'_e']\n",
    "                    test = img2vxy(self.ker_size,self.win_size,self.startxy,self.lengthxy,\n",
    "                                   self.picture_add,v_last+'.jpg',v_end+'.jpg',\n",
    "                                   self.basis_fold_urf+'dataf/',finish_name_urf_fourier,err_name_urf_fourier,\n",
    "                                   self.basis_fold_urf+'datae/',finish_name_urf_equal,err_name_urf_equal)\n",
    "                    state = test.process_equal(self.all_state_list[ii,2],isautosave=is_equal_autosave)\n",
    "\n",
    "                    if state:\n",
    "                        df = pd.read_csv(self.sta_name)\n",
    "                        df.iloc[ii, 4] = 1\n",
    "                        df.to_csv(self.sta_name, index=False)\n",
    "                        print(f'{v_str} finished!')\n",
    "                    else:\n",
    "                        print(f'{v_str} temporarily stopped!')\n",
    "                        if isbreak:\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "                else:\n",
    "\n",
    "                    v_last = str(self.all_state_list[ii,0])\n",
    "                    v_end = str(self.all_state_list[ii,1])\n",
    "                    v_str = v_last+'-'+v_end\n",
    "                    print(f'Start processing: {v_str}')\n",
    "                    finish_name_urf_fourier = [self.file_name[0]+v_str+'_f',self.file_name[1]+v_str+'_f',self.file_name[2]+v_str+'_f']\n",
    "                    err_name_urf_fourier = ['err_'+self.file_name[0]+v_str+'_f','err_'+self.file_name[1]+v_str+'_f','err_'+self.file_name[2]+v_str+'_f']\n",
    "                    finish_name_urf_equal = [self.file_name[0]+v_str+'_e',self.file_name[1]+v_str+'_e',self.file_name[2]+v_str+'_e']\n",
    "                    err_name_urf_equal = ['err_'+self.file_name[0]+v_str+'_e','err_'+self.file_name[1]+v_str+'_e','err_'+self.file_name[2]+v_str+'_e']\n",
    "                    test = img2vxy(self.ker_size,self.win_size,self.startxy,self.lengthxy,\n",
    "                                   self.picture_add,v_last+'.jpg',v_end+'.jpg',\n",
    "                                   self.basis_fold_urf+'dataf/',finish_name_urf_fourier,err_name_urf_fourier,\n",
    "                                   self.basis_fold_urf+'datae/',finish_name_urf_equal,err_name_urf_equal)\n",
    "                    state = test.process_fourier()\n",
    "                    if state:\n",
    "                        df = pd.read_csv(self.sta_name)\n",
    "                        df.iloc[ii, 3] = 1\n",
    "                        df.to_csv(self.sta_name, index=False)\n",
    "                        print(f'{v_str} finished!')\n",
    "                    else:\n",
    "                        print(f'{v_str} temporarily stopped!')\n",
    "                        if isbreak:\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "                    state = test.process_equal(self.all_state_list[ii,2],isautosave=is_equal_autosave,is_used_fourier=True)\n",
    "                    if state:\n",
    "                        df = pd.read_csv(self.sta_name)\n",
    "                        df.iloc[ii, 4] = 1\n",
    "                        df.to_csv(self.sta_name, index=False)\n",
    "                        print(f'{v_str} finished!')\n",
    "                    else:\n",
    "                        print(f'{v_str} temporarily stopped!')\n",
    "                        if isbreak:\n",
    "                            break\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "    def print_v(self,v,cmin,cmax,title=None):\n",
    "        x = range(v.shape[1])\n",
    "        y = range(v.shape[0])\n",
    "        allx,ally = np.meshgrid(x,y)\n",
    "        fig,ax = plt.subplots()\n",
    "        cr = ax.pcolormesh(allx,ally,v,cmap='coolwarm',vmin=cmin,vmax=cmax)\n",
    "        fig.colorbar(cr,ax=ax)\n",
    "        ax.invert_yaxis()\n",
    "        if title != None:\n",
    "            plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "    def which_v(self,type,number,state=0):\n",
    "        v_last = str(self.all_state_list[number,0])\n",
    "        v_end = str(self.all_state_list[number+1,0])\n",
    "        v_str = v_last+'-'+v_end\n",
    "        finish_name_urf_fourier = [self.file_name[0]+v_str+'_f',self.file_name[1]+v_str+'_f',self.file_name[2]+v_str+'_f']\n",
    "        # err_name_urf_fourier = ['err_'+self.file_name[0]+v_str+'_f','err_'+self.file_name[1]+v_str+'_f','err_'+self.file_name[2]+v_str+'_f']\n",
    "        finish_name_urf_equal = [self.file_name[0]+v_str+'_e',self.file_name[1]+v_str+'_e',self.file_name[2]+v_str+'_e']\n",
    "        # err_name_urf_equal = ['err_'+self.file_name[0]+v_str+'_e','err_'+self.file_name[1]+v_str+'_e','err_'+self.file_name[2]+v_str+'_e']\n",
    "        if type=='f':\n",
    "            if state==0:\n",
    "                df = pd.read_csv(self.basis_fold_urf+'dataf/'+finish_name_urf_fourier[0]+'.csv')\n",
    "                self.print_v((np.array(df)-self.win_size//2+self.ker_size//2)/self.all_state_list[number,3],-3,3,v_str)\n",
    "                df = pd.read_csv(self.basis_fold_urf+'dataf/'+finish_name_urf_fourier[1]+'.csv')\n",
    "                self.print_v((np.array(df)-self.win_size//2+self.ker_size//2)/self.all_state_list[number,3],-3,3,v_str)\n",
    "            elif state==1:\n",
    "                df = pd.read_csv(self.basis_fold_urf+'dataf/'+finish_name_urf_fourier[0]+'.csv')\n",
    "                self.print_v((np.array(df)-self.win_size//2+self.ker_size//2)/self.all_state_list[number,3],-3,3,v_str)\n",
    "            else:\n",
    "                df = pd.read_csv(self.basis_fold_urf+'dataf/'+finish_name_urf_fourier[1]+'.csv')\n",
    "                self.print_v((np.array(df)-self.win_size//2+self.ker_size//2)/self.all_state_list[number,3],-3,3,v_str)\n",
    "\n",
    "        if type=='e':\n",
    "            if state==0:\n",
    "                df = pd.read_csv(self.basis_fold_urf+'datae/'+finish_name_urf_equal[0]+'.csv')\n",
    "                self.print_v((np.array(df))/self.all_state_list[number,3],-2.5,2.5,v_str)\n",
    "                df = pd.read_csv(self.basis_fold_urf+'datae/'+finish_name_urf_equal[1]+'.csv',)\n",
    "                self.print_v((np.array(df))/self.all_state_list[number,3],-2.5,2.5,v_str)\n",
    "            elif state==1:\n",
    "                df = pd.read_csv(self.basis_fold_urf+'datae/'+finish_name_urf_equal[0]+'.csv')\n",
    "                self.print_v((np.array(df))/self.all_state_list[number,3],-2.5,2.5,v_str)\n",
    "            else:\n",
    "                df = pd.read_csv(self.basis_fold_urf+'datae/'+finish_name_urf_equal[1]+'.csv',)\n",
    "                self.print_v((np.array(df))/self.all_state_list[number,3],-2.5,2.5,v_str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "'''\n",
    "The coefficients of the class:\n",
    "    basis_fold: storage of the all workflow data\n",
    "    sta_name: statistics file\n",
    "    file_name: prefix name of the results\n",
    "    picture_add: address of the images\n",
    "    ker_size: size of search window\n",
    "    win_size: size of search range\n",
    "    startxy: topleft point of the result\n",
    "    lengthxy: size of results\n",
    "'''\n",
    "\n",
    "ker_size = 45\n",
    "win_size = 201\n",
    "startij = [300,300]\n",
    "lengthij = [3000,3000]\n",
    "\n",
    "basis_fold = 'test\\\\'\n",
    "picture_add = 'Pictures\\jpg\\\\'\n",
    "sta_name = 'statistics.xlsx'\n",
    "file_name = ['vx','vy','isprocessed']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing: 20180401-20180417\n",
      "Reading secondary temporary task...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1500 [00:00<?, ?it/s]C:\\Users\\1\\AppData\\Local\\Temp\\ipykernel_24468\\3666629539.py:390: RuntimeWarning: invalid value encountered in divide\n",
      "  tmp = tmp/np.abs(tmp)\n",
      "100%|██████████| 1500/1500 [09:54<00:00,  2.52it/s]\n",
      " 43%|████▎     | 643/1500 [11:56<15:15,  1.07s/it]  "
     ]
    }
   ],
   "source": [
    "start = process_all(basis_fold,sta_name,file_name,picture_add,ker_size,win_size,startij,lengthij)\n",
    "start.forward('dfe',True,False)\n",
    "\n",
    "'''\n",
    "The coefficients of the forward function:\n",
    "1, type:\n",
    "    'f': only Fourier procession, with statistics column: ['date_{i}', 'date_{i+1}-date_{i}', isFourier, isSecondary]\n",
    "    'e': only secondary procession, with statistics column: ['date_{i}', 'date_{i+1}-date_{i}', isFourier, isSecondary]\n",
    "    'fe': Fourier and secondary procession, with statistics column: ['date_{i}', 'date_{i+1}-date_{i}', isFourier, isSecondary]\n",
    "    'dfe': Fourier and secondary procession, with statistics column: ['date1', 'date2', 'date2-date1', isFourier, isSecondary]\n",
    "2, isbreak:\n",
    "    True: Stop the program after interruption\n",
    "    False: Perform the next registration (if there is) after interruption\n",
    "3, is_equal_autosave:\n",
    "    True: Perform automatic saving in secondary processing\n",
    "    False: Do not perform automatic saving in secondary processing\n",
    "'''"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}